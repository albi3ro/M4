{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 in Julia\n",
    "\n",
    "So last summer, my program was producing three dimensional data, and I needed a way to export and save that data from my C++ program.  Simple ASCII files, my default method, no longer covered my needs.  Of course, I wasn't the first person to encounter this problem, so I discovered the HDF5 standard.  \n",
    "\n",
    "Instead of storing data in a human readable format like ASCII, the Hierarchical Data Format, HDF, stores data in binary format.  This preserves the shape of the data in the computer and keeps it at its minimum size.  WOHOO!!\n",
    "\n",
    "Sadly, the syntax for HDF5 in C++ and Fortran is just as bad as FFTW or OpenBLAS.  But happily, just like FFTW and OpenBLAS, HDF5 has wonderful syntax in Julia, Python, and MATLAB, amoung others.\n",
    "\n",
    "So how does it work? \n",
    "\n",
    "We don't just print a single variable.  Each HDF5 file is like its own file system.  In my home directory, I have my documents folder, my programming folder, my pictures, configuration files,... and inside each folder I can have subfolders or files.  \n",
    "\n",
    "The same is true for an HDF5 file.  We have the root, and then we have groups and subgroups.  A group is like a folder.  Then we can have datasets. Datasets are objects that hold data (files).  \n",
    "\n",
    "\n",
    "## Installing the Package\n",
    "\n",
    "While adding Julia's HDF5 package will hopefully add the HDF5 library as well, additional steps may be required. [Anaconda](https://www.anaconda.com/) can provide the system binaries.  After adding HDF5.jl, Julia may need to build it.  At the REPL, this can be done in package mode by:\n",
    "\n",
    "    (M4) pkg> build HDF5\n",
    "    \n",
    "or more with `Pkg` itself\n",
    "\n",
    "    using Pkg\n",
    "    Pkg.build(\"HDF5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using HDF5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello World \n",
    "First let's open a file and then write some data to it.\n",
    "\n",
    "We can open a file in three ways:\n",
    "\n",
    "|Symbol| Meaning|\n",
    "|-----| ------|\n",
    "|\"w\"| Write.  Will overwrite anything already there.|\n",
    "|\"r\" |Ready-only.|\n",
    "|\"r+\"| Read-write. Preserving existing contents. | \n",
    "\n",
    "If we open with this syntax, we have to always remember to close it with `close()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid=h5open(\"test.h5\",\"w\")\n",
    "\n",
    "fid[\"string\"]=\"Hello World\"\n",
    "\n",
    "close(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigating a File\n",
    "\n",
    "Now let's see if we were successful by reading.  Instead of reading the dataset, we are going to checkout the structure of the file first.  \n",
    "\n",
    "`names(fid)` tells us what is inside the location `fid`.  \n",
    "\n",
    "Both these functions help you find your way around a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names \n",
      "[\"string\"]\n"
     ]
    }
   ],
   "source": [
    "fid=h5open(\"test.h5\",\"r\")\n",
    "\n",
    "println(\"names \\n\",names(fid))\n",
    "\n",
    "close(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data\n",
    "Now when we are reading data, we need to know the difference between dataset and the data the dataset contains. \n",
    "\n",
    "Look at the below example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataset: \tHDF5Dataset\n",
      "the string: \tString\tHello World\n",
      "read another way: \tString\tHello World\n"
     ]
    }
   ],
   "source": [
    "fid=h5open(\"test.h5\",\"r\")\n",
    "\n",
    "dset=fid[\"string\"]\n",
    "println(\"the dataset: \\t\", typeof(dset))\n",
    "\n",
    "data=read(dset)\n",
    "println(\"the string: \\t\", typeof(data),\"\\t\",data)\n",
    "\n",
    "data2=read(fid,\"string\")\n",
    "println(\"read another way: \\t\", typeof(data2),\"\\t\",data2)\n",
    "\n",
    "close(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset is like the filename \"fairytale.txt\", so we then need to read the file to get \"Once upon a time ...\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groups\n",
    "So I've talked about groups, but we haven't done anything with them yet. So let's make some groups!\n",
    "\n",
    "Here we use `g_create` to create two groups, one inside the other.  For the subgroup, it's parent is `g`, so we have to create it at location `g`.  Just like in a filesystem, it's name/ path is nested within its parent's path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " path of h:  /mygroup/mysubgroup\n"
     ]
    }
   ],
   "source": [
    "fid=h5open(\"test.h5\",\"w\")\n",
    "\n",
    "g=g_create(fid,\"mygroup\");\n",
    "h=g_create(g,\"mysubgroup\");\n",
    "\n",
    "println(\"\\n path of h:  \",name(h))\n",
    "\n",
    "close(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes\n",
    "\n",
    "Say in a file I want to include the information that I ran the simulation with 100 sites, at 1 Kelvin, for 100,000 timesteps.  Instead of creating new datasets for each of these individual numbers, I can create attributes and tie them to either a group or a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typeof attrs: \tHDF5.HDF5Attributes\n",
      "Temp: \t1\n",
      "N Sites: \t100\n"
     ]
    }
   ],
   "source": [
    "fid=h5open(\"test.h5\",\"w\")\n",
    "\n",
    "fid[\"data\"]=randn(3,3);\n",
    "\n",
    "attrs(fid[\"data\"])[\"Temp\"]=\"1\";\n",
    "attrs(fid[\"data\"])[\"N Sites\"]=\"100\";\n",
    "\n",
    "close(fid)\n",
    "\n",
    "fid=h5open(\"test.h5\",\"r\")\n",
    "\n",
    "dset=fid[\"data\"];\n",
    "\n",
    "println(\"typeof attrs: \\t\", typeof(attrs(dset)))\n",
    "println(\"Temp: \\t\",read( attrs(dset),\"Temp\"  ))\n",
    "println(\"N Sites: \\t\",read(  attrs(dset),\"N Sites\"  ))\n",
    "\n",
    "close(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Tips\n",
    "\n",
    "Before diving in to learn how to use this, think about whether you need it or not.  How large and complex is your data?  Is it worth the time to learn?  While the syntax might be relatively simple in Julia, ASCII files are still much easier to deal with.  \n",
    "\n",
    "If you are going to play around or use this format, I recommend getting an HDF viewer, like https://www.hdfgroup.org/products/java/release/download.html While you can have much more control via code, sometimes it is just that much simpler to check everything is working via a GUI.   \n",
    "\n",
    "\n",
    "For more information, checkout the Package page at https://github.com/JuliaLang/HDF5.jl or the HDFGroup page at https://www.hdfgroup.org/\n",
    "\n",
    "I just showed some of the functionality in test cases.  As much control as you want, you can get; you might just have to work a bit for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.5",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
